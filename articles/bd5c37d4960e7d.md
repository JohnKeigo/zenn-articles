---
title: "Running Waifu Diffusion with energy saving vram on Windows"
emoji: "ðŸŽƒ"
type: "tech" # tech: technical article / idea: idea
topics: [stable diffusion,waifu diffusion,git,docker,gradio]
published: false
---
Setting up an environment for AUTOMATIC1111's repository in Windows environment
https://github.com/AUTOMATIC1111/stable-diffusion-webui



â–¼ Execution environment
Edition Windows 11 Pro
Version 21H2
OS build 22000.1098
Experience Windows Feature Experience Pack 1000.22000.1098.0

GPU: GTX 1060


# 1 Clone the repository
As in the previous article, the prerequisite is to create an appropriate git repository on Ubuntu and clone the repository.

```js
> git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui
```

Also, download the model files from hugging face and put them under the models/stable-diffusion folder.
I used Waifu Diffusion v1.3 models with float16.

I believe you can download it from here
https://huggingface.co/hakurei/waifu-diffusion-v1-3/blob/main/wd-v1-3-float16.ckpt

```js
â”œâ”€â”€Stable-diffusion
â”‚ Put Stable Diffusion checkpoints here.txt
â”‚ wd-v1-3-float16.ckpt
```

# 2 In my case, I use Anaconda to create a virtual environment to maintain my Python environment, so I install Anaconda Navigator for Windows.
https://www.anaconda.com/products/distribution

# 3 Run Anaconda PowerShell Prompt
Anaconda PowerShell Prompt is installed with Anaconda Navigator by default.

If you feel that you are missing a package when running WebUI, try installing the package in the Anaconda environment and see if it works.
```js
> pip install -r requirements.txt
```

# 4 Run webui.bat
```js
> cd stable-diffusion-webui
> . /webui.bat
venv "C:\Users\keigo\git\stable-diffusion-webui\venvScripts\Python.exe"
Python 3.9.12 (main, Apr 4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)].
Commit hash: 1fbfc052eb529d8cf8ce5baf578bcf93d0280c29
Installing requirements for Web UI
Launching Web UI with arguments:
LatentDiffusion: Running in eps-prediction mode
DiffusionWrapper has 859.52 M params.
Making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 4, 32, 32) = 4096 dimensions.
Working with z of shape (1, 4, 32, 32) = 4096 dimensions. making attention of type 'vanilla' with 512 in_channels
Loading weights [84692140] from C:\Users\keigo\git\stable-diffusion-webui\models\Stable-diffusion\wd-v1-3-float16.ckpt
Global Step: 683410
Applying cross attention optimization (Doggettx).
Model loaded.
Loaded a total of 0 textual inversion embeddings.
Embeddings:
Running on local URL: http://127.0.0.1:7860

To create a public link, set `share=True` in `launch()`.

```

# 5 The service runs on http://127.0.0.1:7860, so access it, put in the prompt and draw!
! [](https://storage.googleapis.com/zenn-user-upload/12ebf42e4d0f-20221106.png)
It took about 20-30 seconds to generate the image.

# 6 vram during drawing consumed about 4.3GB!

It seems that a model with float16 precision can be used to generate a 512x512 image on a GTX 1060 GPU with about 6GB of vram.

! [](https://storage.googleapis.com/zenn-user-upload/ba6e9d06f59d-20221106.png)

# Thanks
Thanks to everyone behind these awesome projects, 
First I would like to contribute the project by introducing the best environment run with the user PC environment.
And I will contribute the democratized AI through this activity.

AbdBarho/stable-diffusion-webui-docker#thanks
hlky/stable-diffusion-webui
AUTOMATIC1111/stable-diffusion-webui
lstein/stable-diffusion
CompVis/stable-diffusion
hlky/sd-enable-textual-inversion
devilismyfriend/latent-diffusion
Hafiidz/latent-diffusion

Translated with www.DeepL.com/Translator (free version)